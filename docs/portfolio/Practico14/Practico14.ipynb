{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IfnYTXjr7UC1",
        "outputId": "f11aeb85-ac80-417a-c6a6-f7e91537cf18"
      },
      "outputs": [],
      "source": [
        "# Instalación (Colab/Local)\n",
        "# Instalación (Colab/Local)\n",
        "!pip install -U \"langchain>=0.2.11\" \"langchain-core>=0.2.33\" \"langchain-community>=0.2.11\" \"langchain-openai>=0.2.1\" \"langsmith>=0.1.97\"\n",
        "# Opcionales para el assignment:\n",
        "!pip install -U faiss-cpu chromadb tavily-python duckduckgo-search langchain-text-splitters\n",
        "\n",
        "import os\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"api-key\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"api-key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhq--9wOBXaa",
        "outputId": "8e5d74e0-30e5-42d5-8a03-7982bddb724e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Un Transformer es una arquitectura de red neuronal que usa mecanismos de atención (self-attention) para modelar dependencias de largo alcance en secuencias y procesarlas en paralelo para tareas como traducción y comprensión de lenguaje.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)  # modelo sugerido\n",
        "\n",
        "# Hola LLM\n",
        "resp = llm.invoke(\"Definí 'Transformer' en una sola oración.\")\n",
        "print(resp.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPmOxrgCMMYP",
        "outputId": "10f3f2d7-876c-4030-cc6f-8b1a7fafaecb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mi versión: ChatGPT — modelo GPT-4o de OpenAI.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Completar parámetros básicos (ver [1] y [12])\n",
        "MODEL = \"gpt-5-mini\"\n",
        "TEMP = 0\n",
        "\n",
        "llm = ChatOpenAI(model=MODEL, temperature=TEMP)\n",
        "print(llm.invoke(\"Hola! Decime tu versión en una línea.\").content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg8rI7QFMeDc",
        "outputId": "e38e1858-3a8d-4d6a-f7bc-81a46a19610e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mide la verdad\n",
            "curva, ruido y sesgo\n",
            "aprende siempre\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "MODEL = \"gpt-5-mini\"\n",
        "TEMP = 0\n",
        "\n",
        "llm = ChatOpenAI(model=MODEL, temperature=TEMP)\n",
        "print(llm.invoke(\"Escribí un haiku sobre evaluación de modelos.\").content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlJbalU_MoQU",
        "outputId": "3dae4673-ecc3-4f35-d91e-07b8ee56ecac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La atención multi-cabeza proyecta consultas, claves y valores en varias subespacios (cabezas), calcula en cada uno la atención por producto punto escalada y concatena esas salidas para una proyección final.  \n",
            "Así el modelo puede atender simultáneamente a distintos tipos de relaciones (p. ej. sintácticas vs. semánticas) y a distintos rangos posicionales.  \n",
            "Ejemplo: en traducción, una cabeza puede alinear \"El gato\"→\"The cat\" mientras otra identifica la relación verbo‑objeto para ordenar y elegir la forma verbal correcta al generar \"eats the fish\".\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Sos un asistente conciso, exacto y profesional.\"),\n",
        "    (\"human\",  \"Explicá {tema} en <= 3 oraciones, con un ejemplo real.\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm  # LCEL: prompt → LLM\n",
        "print(chain.invoke({\"tema\": \"atención multi-cabeza\"}).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5ISxnM8Ms2U",
        "outputId": "dbb114ae-f3e6-4568-b461-08efce06a1fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Resumen(title='Riesgos de la prompt injection en aplicaciones con LLM', bullets=['Ejecución de instrucciones maliciosas: el atacante puede inducir al modelo a realizar acciones no autorizadas (exfiltrar datos, ejecutar comandos, acceder a recursos) comprometiendo seguridad operacional.', 'Manipulación del comportamiento del modelo: prompts maliciosos pueden inducir respuestas incorrectas, sesgadas o que evadan filtros y mecanismos de seguridad, generando desinformación y fallas de control.', 'Pérdida de privacidad y confianza: exposición de datos sensibles, filtrado de información confidencial y daño reputacional o legal para la organización que despliega la aplicación.'])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Resumen(BaseModel):\n",
        "    title: str\n",
        "    bullets: List[str]\n",
        "\n",
        "llm_json = llm.with_structured_output(Resumen)  # garantiza JSON válido que cumple el esquema\n",
        "\n",
        "pedido = \"Resumí en 3 bullets los riesgos de la 'prompt injection' en LLM apps.\"\n",
        "res = llm_json.invoke(pedido)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHbCgVGBM0hc",
        "outputId": "1c7c2685-f13c-4bf6-b2ec-3bf169186bdc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traza enviada (ver LangSmith).\n"
          ]
        }
      ],
      "source": [
        "_ = (prompt | llm).invoke({\"tema\": \"transformers vs RNNs\"})\n",
        "print(\"Traza enviada (ver LangSmith).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtus0daVNWs4",
        "outputId": "ea7768e4-c8d2-4585-b429-c30168f58f0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text='Excelente trabalho da equipe' lang='pt'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Permite producir salida estructurada en formato JSON.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 211, 'prompt_tokens': 54, 'total_tokens': 265, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CartqNO8X1jArrSCzSBmB8dCYgHXY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--87795517-802e-413f-a454-846edaed9920-0' usage_metadata={'input_tokens': 54, 'output_tokens': 211, 'total_tokens': 265, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}\n"
          ]
        }
      ],
      "source": [
        "# Esqueleto sugerido para 1) y 2)\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Traduccion(BaseModel):\n",
        "    text: str\n",
        "    lang: str\n",
        "\n",
        "traductor = llm.with_structured_output(Traduccion)\n",
        "salida = traductor.invoke(\"Traducí al portugués: 'Excelente trabajo del equipo'.\")\n",
        "print(salida)\n",
        "\n",
        "# Q&A con contexto (sin RAG)\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "QA_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Respondé SOLO usando el contexto. Si no alcanza, decí 'No suficiente contexto'.\"),\n",
        "    (\"human\",  \"Contexto:\\n{contexto}\\n\\nPregunta: {pregunta}\\nRespuesta breve:\")\n",
        "])\n",
        "salida = (QA_prompt | llm).invoke({\n",
        "    \"contexto\": \"OpenAI y LangChain permiten structured output con JSON...\",\n",
        "    \"pregunta\": \"¿Qué ventaja tiene structured output?\"\n",
        "})\n",
        "print(salida)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h1Zw-2WOhql",
        "outputId": "81b65049-1e15-45d8-c407-979b261290ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Zero-shot ==\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEG\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEU\n",
            "\n",
            "== Few-shot ==\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Etiqueta: NEG\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEU\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
        "\n",
        "# Zero-shot\n",
        "zs_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Sos un asistente conciso y exacto.\"),\n",
        "    (\"human\",  \"Clasificá el sentimiento de este texto como POS, NEG o NEU:\\n\\n{texto}\")\n",
        "])\n",
        "\n",
        "# Few-shot (1–2 ejemplos)\n",
        "fs_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Sos un asistente conciso y exacto.\"),\n",
        "    (\"human\",  \"Ejemplo:\\nTexto: 'El producto superó mis expectativas'\\nEtiqueta: POS\"),\n",
        "    (\"human\",  \"Ejemplo:\\nTexto: 'La entrega fue tarde y vino roto'\\nEtiqueta: NEG\"),\n",
        "    (\"human\",  \"Texto: {texto}\\nEtiqueta:\")\n",
        "])\n",
        "\n",
        "textos = [\n",
        "    \"Me encantó la experiencia, repetiría.\",\n",
        "    \"No cumple lo prometido; decepcionante.\",\n",
        "    \"Está bien, nada extraordinario.\"\n",
        "]\n",
        "\n",
        "print(\"== Zero-shot ==\")\n",
        "for t in textos:\n",
        "    print((zs_prompt | llm).invoke({\"texto\": t}).content)\n",
        "\n",
        "print(\"\\n== Few-shot ==\")\n",
        "for t in textos:\n",
        "    print((fs_prompt | llm).invoke({\"texto\": t}).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_hUOy7IOsKU",
        "outputId": "870ba2ee-204a-40e9-e026-5a7723fb1be4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ribamoura, pueblo fronterizo famoso por el contrabando, vivía de él: joyas y sedas, ron y quesos, armas y tabacos entraban por Portugal o cruzando el río. La actividad, arriesgada y lucrativa, marcaba la conducta social (se valoraba a quien salía armado). El pueblo se reunía en festejos tradicionales—Carnaval, la Patrona y una Semana Santa festiva con una Pasión representada por vecinos bajo la dirección de un actor de Oporto—siempre devota y excluyente de mercenarios. Aun contrabandistas, se consideraban gente honrada; los frailes no lo veían como pecado.\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "long_text = \"\"\"A lo Vivo\n",
        "Era un pueblecito rayano, Ribamoura, vivero de contrabandistas, donde esta profesión de riesgo y lucro hacía a la gente menos dormida de lo que suelen ser los pueblerinos. Abundaban los mozos de cabeza caliente, y se desdeñaba al que no era capaz de coger una escopeta y salir a la ganancia.\n",
        "\n",
        "Las mujeres, vestidas y adornadas con lo que da de sí el contrabando, lucían pendientes de ostentosa filigrana, patenas fastuosas, pañuelos de seda de colorines; en las casas no faltaba ron jamaiqueño ni queso de Flandes, y los hombres poseían armas inglesas, bolsas de piel y tabaco Virginia y Macuba. Al través de Portugal, Inglaterra enviaba sus productos, y de España pasaban otros, cruzando el caudaloso río.\n",
        "\n",
        "Algunos días del año se interrumpía el tráfico y la industria de Ribamoura. El pueblo entero se congregaba a celebrar las solemnidades consuetudinarias, que servían de pretexto para solaces y holgorio. Tal ocurría con el Carnaval, tal con la fiesta de la Patrona, tal con los días de la Semana Santa. A pesar de ser éstos de penitencia y mortificación, para los de Ribamoura tenían carácter de fiesta; en ellos se celebraba, en la iglesia principal, espacioso edificio de la época herreriana, la representación de la Pasión, con personajes de carne y hueso, y encargándose de los papeles gente del pueblo mismo.\n",
        "\n",
        "Venido de Oporto, un actor portugués, con el instinto dramático de la raza, organizaba y dirigía la representación; pero sin tomar parte en ella. Esto se hubiese considerado en Ribamoura irreverente. «Trabajaban» por devoción y por respeto tradicional a los misterios redentores; pero nunca hubiesen admitido a nadie mercenario, ni tolerado que hiciese los papeles nadie de mala reputación. Gente honrada, aunque contrabandease; que eso no deshonra. Ni por pecado lo daban en el confesionario los frailes.\"\"\"\n",
        "\n",
        "# Split en chunks\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)\n",
        "chunks = splitter.split_text(long_text)\n",
        "\n",
        "# Cadena para resumir un chunk\n",
        "chunk_summary_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Resumí el siguiente fragmento en 2–3 bullets, claros y factuales.\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
        "chunk_summary = chunk_summary_prompt | llm\n",
        "\n",
        "bullets = [chunk_summary.invoke({\"input\": c}).content for c in chunks]\n",
        "\n",
        "# Reduce (combinar resultados)\n",
        "reduce_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Consolidá bullets redundantes y producí un resumen único y breve.\"),\n",
        "    (\"human\", \"Bullets:\\n{bullets}\\n\\nResumen final (<=120 tokens):\")\n",
        "])\n",
        "\n",
        "final = (reduce_prompt | llm).invoke({\"bullets\": \"\\n\".join(bullets)}).content\n",
        "print(final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT_FimaPQStg",
        "outputId": "a240c5cc-9110-4760-ba6c-92123b1e69f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ExtractInfo(titulo=None, fecha='05/11/2025', entidades=[Entidad(tipo='ORG', valor='OpenAI'), Entidad(tipo='ORG', valor='Universidad Catolica del Uruguay'), Entidad(tipo='LOC', valor='Montevideo')])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import List, Optional\n",
        "from pydantic import BaseModel\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
        "\n",
        "class Entidad(BaseModel):\n",
        "    tipo: str   # p.ej., 'ORG', 'PER', 'LOC'\n",
        "    valor: str\n",
        "\n",
        "class ExtractInfo(BaseModel):\n",
        "    titulo: Optional[str]\n",
        "    fecha: Optional[str]\n",
        "    entidades: List[Entidad]\n",
        "\n",
        "extractor = llm.with_structured_output(ExtractInfo)\n",
        "texto = \"OpenAI anunció una colaboración con la Universidad Catolica del Uruguay en Montevideo el 05/11/2025.\"\n",
        "extractor.invoke(f\"Extraé titulo, fecha y entidades (ORG/PER/LOC) del siguiente texto:\\n\\n{texto}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpeW98ThQW8H",
        "outputId": "9f711c91-1d2a-4f39-f1f3-b3dd09474c70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': '¿Qué ventaja clave aporta RAG?',\n",
              " 'context': [Document(id='072d06e5-4c87-4cdf-b74c-04b8e5ce5b98', metadata={}, page_content='RAG combina recuperación + generación para mejor grounding.'),\n",
              "  Document(id='a43dd93c-7eb4-4337-9091-bd377854c8d1', metadata={}, page_content='OpenAIEmbeddings facilita embeddings para indexar textos.'),\n",
              "  Document(id='b581ab9d-5f73-4f84-a3ec-2da4b000da88', metadata={}, page_content='LangChain soporta structured output con Pydantic.')],\n",
              " 'answer': 'RAG combina recuperación + generación para mejor grounding.\\n\\nOpenAIEmbeddings facilita embeddings para indexar textos.\\n\\nLangChain soporta structured output con Pydantic.'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS  # Si usás Chroma, importá su VectorStore\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_classic.chains.combine_documents.stuff import create_stuff_documents_chain\n",
        "from langchain_classic.chains import create_retrieval_chain\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "docs_raw = [\n",
        "    \"LangChain soporta structured output con Pydantic.\",\n",
        "    \"RAG combina recuperación + generación para mejor grounding.\",\n",
        "    \"OpenAIEmbeddings facilita embeddings para indexar textos.\"\n",
        "]\n",
        "docs = [Document(page_content=t) for t in docs_raw]\n",
        "\n",
        "# Split y vector store\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "emb = OpenAIEmbeddings()\n",
        "vs = FAISS.from_documents(chunks, embedding=emb)\n",
        "retriever = vs.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Respondé SOLO con el contexto. Si no alcanza, decí 'No suficiente contexto'.\"),\n",
        "    (\"human\",  \"Contexto:\\n{context}\\n\\nPregunta: {input}\")\n",
        "])\n",
        "\n",
        "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
        "\n",
        "rag_chain.invoke({\"input\": \"¿Qué ventaja clave aporta RAG?\"})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
